{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ƒê·ªì √°n m√¥n h·ªçc**\n",
    "## M√¥n: L·∫≠p tr√¨nh song song ·ª©ng d·ª•ng\n",
    "### L·ªõp CQ2021/21 - Nh√≥m 05\n",
    "#### Th√†nh vi√™n:\n",
    "| H·ªç v√† t√™n             | MSSV |\n",
    "| :-----------          |     :----:|\n",
    "| Di·ªáp ƒê·∫°i Thi·ªán Nh√¢n | 18120491  |\n",
    "| Ho√†ng Trung Nam  | 21120290 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **T·ªïng quan ƒë·ªì √°n**\n",
    "\n",
    "- Nh√≥m quy·∫øt ƒë·ªãnh th·ª≠ s·ª©c v·ªõi VGG.\n",
    "\n",
    "- VGG l√† m·ªôt ki·∫øn tr√∫c CNN s√¢u ƒë∆∞·ª£c gi·ªõi thi·ªáu b·ªüi nh√≥m VGG (Visual Geometry Group) thu·ªôc ƒê·∫°i h·ªçc Oxford nƒÉm 2014. Ki·∫øn tr√∫c n√†y n·ªïi b·∫≠t b·ªüi vi·ªác s·ª≠ d·ª•ng nhi·ªÅu l·ªõp convolution 3x3 li√™n ti·∫øp thay v√¨ m·ªôt l·ªõp convolution l·ªõn (vd: 5x5 hay 7x7), nh·∫±m tƒÉng kh·∫£ nƒÉng h·ªçc ƒë·∫∑c tr∆∞ng v√† gi·ªØ k√≠ch th∆∞·ªõc receptive field ·ªïn ƒë·ªãnh.\n",
    "\n",
    "- Hai phi√™n b·∫£n ph·ªï bi·∫øn:\n",
    "  - VGG-16: 16 l·ªõp c√≥ tr·ªçng s·ªë (13 conv + 3 FC).\n",
    "  - VGG-19: 19 l·ªõp c√≥ tr·ªçng s·ªë (16 conv + 3 FC).\n",
    "\n",
    "- **Input c·ªßa CIFAR-10** l√† `32x32x3`, nh·ªè h∆°n r·∫•t nhi·ªÅu so v·ªõi `224x224x3` c·ªßa VGG g·ªëc.\n",
    "\n",
    "V·∫≠y n√™n, khi √°p d·ª•ng VGG cho CIFAR-10, ta c·∫ßn **gi·∫£m s·ªë l∆∞·ª£ng layer** ho·∫∑c **ƒëi·ªÅu ch·ªânh input size** nh∆∞ sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ki·∫øn tr√∫c m√¥ h√¨nh c·ª• th·ªÉ**\n",
    "\n",
    "- **Input Layer**  \n",
    "  - 32√ó32√ó3 (RGB)\n",
    "\n",
    "- **Block 1**  \n",
    "  - Conv3√ó3, 64 filters + ReLU  \n",
    "  - Conv3√ó3, 64 filters + ReLU  \n",
    "  - MaxPool 2√ó2\n",
    "\n",
    "- **Block 2**  \n",
    "  - Conv3√ó3, 128 filters + ReLU  \n",
    "  - Conv3√ó3, 128 filters + ReLU  \n",
    "  - MaxPool 2√ó2\n",
    "\n",
    "- **Block 3**  \n",
    "  - Conv3√ó3, 256 filters + ReLU  \n",
    "  - Conv3√ó3, 256 filters + ReLU  \n",
    "  - MaxPool 2√ó2\n",
    "\n",
    "- **Fully Connected**  \n",
    "  - FC 512 + ReLU  \n",
    "  - FC 10 + Softmax\n",
    "\n",
    "- **Optimization**  \n",
    "  - Loss: Cross‚ÄëEntropy  \n",
    "  - Optimizer: SGD/Adam  \n",
    "  - Parallelization: Vi·∫øt b·∫±ng Numpy ‚Üí t·ªëi ∆∞u v·ªõi Numba (`@cuda.jit`)\n",
    "\n",
    "Ki·∫øn tr√∫c VGG‚Äëlike n√†y gi·ªØ tinh th·∫ßn ‚Äúnhi·ªÅu conv 3√ó3‚Äù c·ªßa VGG g·ªëc nh∆∞ng thu g·ªçn cho ph√π h·ª£p v·ªõi k√≠ch th∆∞·ªõc ·∫£nh 32√ó32 v√† dataset CIFAR‚Äë10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset**\n",
    "\n",
    "- **CIFAR-10**:\n",
    "  - 60.000 ·∫£nh m√†u 32√ó32 thu·ªôc 10 l·ªõp.\n",
    "\n",
    "  - 50.000 ·∫£nh train, 10.000 ·∫£nh test.\n",
    "\n",
    "  - Link: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **N·ªôi dung ƒë√£ ho√†n th√†nh**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C√†i ƒë·∫∑t h√†m tu·∫ßn t·ª±**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **√ù t∆∞·ªüng**\n",
    "\n",
    "#### üì• Input Layer\n",
    "\n",
    "- K√≠ch th∆∞·ªõc ·∫£nh: **32 √ó 32 √ó 3 (RGB)**  \n",
    "- Sau m·ªói layer, k√≠ch th∆∞·ªõc thay ƒë·ªïi t√πy theo padding v√† pooling.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† 1. Convolutional Layer (3√ó3)\n",
    "\n",
    "**C√¥ng th·ª©c:**\n",
    "\n",
    "$$\n",
    "Y[i,j,cout] = \\sum_{u=0}^{2} \\sum_{v=0}^{2} \\sum_{cin=0}^{C_{in}-1} K[u,v,cin,cout] \\cdot X[i+u, j+v, cin]\n",
    "$$\n",
    "\n",
    "**Ch√∫ th√≠ch bi·∫øn:**\n",
    "- $ X $ : ·∫£nh ƒë·∫ßu v√†o, k√≠ch th∆∞·ªõc (H, W, Cin)\n",
    "- $K$: kernel/l·ªçc, k√≠ch th∆∞·ªõc (3, 3, Cin, Cout)\n",
    "- $Y$: ·∫£nh ƒë·∫ßu ra sau convolution, k√≠ch th∆∞·ªõc (H', W', Cout)\n",
    "- $i, j$: v·ªã tr√≠ kh√¥ng gian\n",
    "- $u, v$: t·ªça ƒë·ªô trong kernel\n",
    "- $cin, cout$: ch·ªâ s·ªë k√™nh ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "\n",
    "**Song song h√≥a:**  \n",
    "‚úî M·ªói ph·∫ßn t·ª≠ $Y[i,j,cout]$ ƒë·ªôc l·∫≠p ‚Üí tri·ªÉn khai b·∫±ng `@cuda.jit` (Numba)\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö° 2. Activation Layer (ReLU)\n",
    "\n",
    "**C√¥ng th·ª©c:**\n",
    "\n",
    "$$\n",
    "A[i,j,c] = \\max(0, Z[i,j,c])\n",
    "$$\n",
    "\n",
    "**Ch√∫ th√≠ch bi·∫øn:**\n",
    "- $Z$ : ƒë·∫ßu ra t·ª´ convolution\n",
    "- $A$: ƒë·∫ßu ra sau k√≠ch ho·∫°t ReLU\n",
    "\n",
    "**Song song h√≥a:**  \n",
    "‚úî M·ªói ph·∫ßn t·ª≠ ƒë·ªôc l·∫≠p ‚Üí d√πng `@vectorize` ho·∫∑c `@cuda.jit`\n",
    "\n",
    "---\n",
    "\n",
    "#### üåä 3. Max Pooling Layer (2√ó2)\n",
    "\n",
    "**C√¥ng th·ª©c:**\n",
    "\n",
    "$$\n",
    "P[i,j,c] = \\max \\begin{Bmatrix}\n",
    "X[2i, 2j, c], & X[2i+1, 2j, c], \\\\\n",
    "X[2i, 2j+1, c], & X[2i+1, 2j+1, c]\n",
    "\\end{Bmatrix}\n",
    "$$\n",
    "\n",
    "**Ch√∫ th√≠ch bi·∫øn:**\n",
    "- $X$: ƒë·∫ßu v√†o tr∆∞·ªõc pooling\n",
    "- $P$: ƒë·∫ßu ra sau pooling\n",
    "- $i, j$: v·ªã tr√≠ tr√™n ·∫£nh pooling\n",
    "- $c$ : k√™nh m√†u\n",
    "\n",
    "**Song song h√≥a:**  \n",
    "‚úî M·ªói v√πng pooling ƒë·ªôc l·∫≠p ‚Üí d√πng `@cuda.jit`\n",
    "\n",
    "---\n",
    "\n",
    "#### üß© 4. Fully Connected Layer (FC)\n",
    "\n",
    "**C√¥ng th·ª©c:**\n",
    "\n",
    "$$\n",
    "y_k = \\sum_{d=0}^{D-1} W[d,k] \\cdot x_d + b_k\n",
    "$$\n",
    "\n",
    "**Ch√∫ th√≠ch bi·∫øn:**\n",
    "- $x$: vector ƒë·∫ßu v√†o ƒë√£ flatten (sau c√°c conv)\n",
    "- $W$: ma tr·∫≠n tr·ªçng s·ªë FC (D, K)\n",
    "- $b$: bias\n",
    "- $y$: output vector\n",
    "\n",
    "**Song song h√≥a:**  \n",
    "‚úî M·ªói $y_k$ ƒë·ªôc l·∫≠p ‚Üí d√πng `@cuda.jit` ho·∫∑c `@njit(parallel=True)`\n",
    "\n",
    "---\n",
    "\n",
    "#### üî• 5. Softmax + Cross-Entropy Loss\n",
    "\n",
    "**Softmax:**\n",
    "\n",
    "$$\n",
    "p_i = \\frac{e^{y_i}}{\\sum_j e^{y_j}}\n",
    "$$\n",
    "\n",
    "**Loss:**\n",
    "\n",
    "$$\n",
    "L = -\\sum_i t_i \\cdot \\log(p_i)\n",
    "$$\n",
    "\n",
    "**Ch√∫ th√≠ch bi·∫øn:**\n",
    "- $y_i$: gi√° tr·ªã ƒë·∫ßu ra t·ª´ FC\n",
    "- $p_i$: x√°c su·∫•t sau softmax\n",
    "- $t_i$: nh√£n th·∫≠t (one-hot)\n",
    "- $L$: h√†m m·∫•t m√°t\n",
    "\n",
    "**Song song h√≥a:**  \n",
    "‚úò Kh√¥ng c·∫ßn, t√≠nh nh·∫π, c√≥ th·ªÉ x·ª≠ l√Ω tr√™n CPU\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ 6. Backpropagation + Weight Update\n",
    "\n",
    "##### Gradient c·ªßa Softmax + CrossEntropy:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial y_i} = p_i - t_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "##### Gradient c·ªßa FC:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W[d,k]} = x_d \\cdot \\frac{\\partial L}{\\partial y_k}\n",
    "\\quad ; \\quad\n",
    "\\frac{\\partial L}{\\partial b_k} = \\frac{\\partial L}{\\partial y_k}\n",
    "$$\n",
    "\n",
    "**Song song h√≥a:** ‚úî t·ª´ng ph·∫ßn t·ª≠ ƒë·ªôc l·∫≠p ‚Üí `@cuda.jit`\n",
    "\n",
    "---\n",
    "\n",
    "##### Gradient c·ªßa ReLU:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z[i,j,c]} = \n",
    "\\begin{cases}\n",
    "\\frac{\\partial L}{\\partial A[i,j,c]}, & \\text{if } Z[i,j,c] > 0 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "##### Gradient c·ªßa Convolution:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial K[u,v,cin,cout]} = \\sum_{i,j} \\frac{\\partial L}{\\partial Y[i,j,cout]} \\cdot X[i+u,j+v,cin]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial X[i,j,cin]} = \\sum_{u,v,cout} \\frac{\\partial L}{\\partial Y[i-u,j-v,cout]} \\cdot K[u,v,cin,cout]\n",
    "$$\n",
    "\n",
    "**Song song h√≥a:** ‚úî n·∫∑ng nh·∫•t ‚Üí d√πng `@cuda.jit` ƒë·ªÉ t·ªëi ∆∞u\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ T√≥m t·∫Øt kh·∫£ nƒÉng song song h√≥a\n",
    "\n",
    "| L·ªõp              | C·∫ßn song song | Ghi ch√∫                                |\n",
    "|------------------|----------------|----------------------------------------|\n",
    "| Convolution       | ‚úÖ              | T√≠nh to√°n n·∫∑ng, ph·∫ßn t·ª≠ ƒë·ªôc l·∫≠p         |\n",
    "| ReLU              | ‚úÖ              | M·ªói ph·∫ßn t·ª≠ t√≠nh ri√™ng ƒë∆∞·ª£c             |\n",
    "| Max Pooling       | ‚úÖ              | M·ªói v√πng pooling ƒë·ªôc l·∫≠p               |\n",
    "| Fully Connected   | ‚úÖ              | M·ªói neuron ƒë·∫ßu ra ƒë·ªôc l·∫≠p              |\n",
    "| Softmax + Loss    | ‚ùå              | T√≠nh nh·∫π, x·ª≠ l√Ω CPU v·∫´n hi·ªáu qu·∫£       |\n",
    "| Backpropagation   | ‚úÖ              | C√°c ƒë·∫°o h√†m c√≥ th·ªÉ t√≠nh ƒë·ªôc l·∫≠p        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chu·∫©n b·ªã d·ªØ li·ªáu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è¨ Downloading CIFAR-10...\n",
      "üì¶ Extracting CIFAR-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WIN 10\\AppData\\Local\\Temp\\ipykernel_9612\\3000658681.py:17: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done.\n"
     ]
    }
   ],
   "source": [
    "# Script n√†y t·∫£i xu·ªëng v√† gi·∫£i n√©n t·∫≠p d·ªØ li·ªáu CIFAR-10 t·ª´ trang web ch√≠nh th·ª©c\n",
    "def download_cifar10():\n",
    "    url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "    filename = 'cifar-10-python.tar.gz'\n",
    "    folder = 'cifar-10-batches-py'\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"‚è¨ Downloading CIFAR-10...\")\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        print(\"üì¶ Extracting CIFAR-10...\")\n",
    "        with tarfile.open(filename, 'r:gz') as tar:\n",
    "            tar.extractall()\n",
    "    print(\"‚úÖ Done.\")\n",
    "\n",
    "download_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CIFAR-10 loaded: (50000, 3, 32, 32) (50000,)\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "def load_batch(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "        images = data[b'data']\n",
    "        labels = data[b'labels']\n",
    "        images = images.reshape(-1, 3, 32, 32)  # N x C x H x W\n",
    "        return images, labels\n",
    "\n",
    "def load_cifar10_data():\n",
    "    base_dir = 'cifar-10-batches-py'\n",
    "    X_train, y_train = [], []\n",
    "\n",
    "    # Load 5 training batches\n",
    "    for i in range(1, 6):\n",
    "        images, labels = load_batch(f'{base_dir}/data_batch_{i}')\n",
    "        X_train.append(images)\n",
    "        y_train += labels\n",
    "\n",
    "    # Load test batch\n",
    "    X_test, y_test = load_batch(f'{base_dir}/test_batch')\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_cifar10_data()\n",
    "print(\"‚úÖ CIFAR-10 loaded:\", X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Normalized CIFAR-10 data: (50000, 3, 32, 32) (50000,)\n",
      "‚úÖ Normalized CIFAR-10 test data: (10000, 3, 32, 32) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# ƒê∆∞a gi√° tr·ªã pixel v·ªÅ [0, 1]\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_test = X_test.astype(np.float32) / 255.0\n",
    "print(\"‚úÖ Normalized CIFAR-10 data:\", X_train.shape, y_train.shape)\n",
    "print(\"‚úÖ Normalized CIFAR-10 test data:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ One-hot encoded CIFAR-10 labels: (50000, 10)\n",
      "‚úÖ One-hot encoded CIFAR-10 test labels: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Chuy·ªÉn ƒë·ªïi nh√£n th√†nh one-hot encoding\n",
    "def one_hot(labels, num_classes=10):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "y_train_oh = one_hot(y_train)\n",
    "y_test_oh = one_hot(y_test)\n",
    "print(\"‚úÖ One-hot encoded CIFAR-10 labels:\", y_train_oh.shape)\n",
    "print(\"‚úÖ One-hot encoded CIFAR-10 test labels:\", y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in c√°c ·∫£nh ng·∫´u nhi√™n\n",
    "def show_random_images(X, y, num_images=5):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(num_images):\n",
    "        idx = random.randint(0, len(X) - 1)\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(X[idx].transpose(1, 2, 0))  # Chuy·ªÉn ƒë·ªïi t·ª´ (C, H, W) sang (H, W, C)\n",
    "        plt.title(f\"Label: {y[idx]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Current directory tree:\n",
      "./\n",
      "    .gitignore\n",
      "    app_group7.ipynb\n",
      "    cifar-10-python.tar.gz\n",
      "    Image_Classification.ipynb\n",
      "    README.md\n",
      "    .git/\n",
      "        COMMIT_EDITMSG\n",
      "        config\n",
      "        description\n",
      "        FETCH_HEAD\n",
      "        HEAD\n",
      "        index\n",
      "        ORIG_HEAD\n",
      "        packed-refs\n",
      "        hooks/\n",
      "            applypatch-msg.sample\n",
      "            commit-msg.sample\n",
      "            fsmonitor-watchman.sample\n",
      "            post-update.sample\n",
      "            pre-applypatch.sample\n",
      "            pre-commit.sample\n",
      "            pre-merge-commit.sample\n",
      "            pre-push.sample\n",
      "            pre-rebase.sample\n",
      "            pre-receive.sample\n",
      "            prepare-commit-msg.sample\n",
      "            push-to-checkout.sample\n",
      "            sendemail-validate.sample\n",
      "            update.sample\n",
      "        info/\n",
      "            exclude\n",
      "        logs/\n",
      "            HEAD\n",
      "            refs/\n",
      "                heads/\n",
      "                    main\n",
      "                    nam\n",
      "                remotes/\n",
      "                    origin/\n",
      "                        HEAD\n",
      "                        main\n",
      "                        nam\n",
      "        objects/\n",
      "            07/\n",
      "                9328c2a857eb6b7eb2d0aec44418331d180f91\n",
      "            0e/\n",
      "                f8504b06a892562db38a0c120e9e92d760fc65\n",
      "            11/\n",
      "                8b07b73afb12255aa0efd88e69918d0842c6d3\n",
      "            17/\n",
      "                8fd27a103cb18e5eb78a463763dc91940e269a\n",
      "            18/\n",
      "                b25703f873f2bd7c2dd2c2216fa77c18f2f418\n",
      "            1e/\n",
      "                6e3ded635faa63d475e95526990d6bf0c62bac\n",
      "            22/\n",
      "                1d68e7ec384cf54aad576ac212709a7093d8c3\n",
      "            24/\n",
      "                639e0e7873c473a4e3a58853000835a7db9e5e\n",
      "            32/\n",
      "                6fd42ae4f09ccb915af09412ae2b0419edfeed\n",
      "            38/\n",
      "                4acb1a35a53d63d0660fa0bf2c98268be5aa33\n",
      "            3e/\n",
      "                6aece0376616de7e25e27af22d1c2dfa667f55\n",
      "            4b/\n",
      "                3f82c61707922e0920904105c24e591f15451e\n",
      "            59/\n",
      "                70c3eb2cddd263855e60af6011357917bd6a88\n",
      "                d5545cdebe9367ad8278e9ca19a848281d05d3\n",
      "            6c/\n",
      "                ffef405097ede7601d642f5f9a89c8728664fd\n",
      "            75/\n",
      "                5edfef617859d07f61b381abd5a04cdcc88bd2\n",
      "                fee1bea326fa0b583bcc3d22e6fcc05181f872\n",
      "            79/\n",
      "                bf8161988ac80f26ae596c6ea7240abe214c6b\n",
      "            7e/\n",
      "                5a57fa88e76378fcffbda151424b1d5b71e6d4\n",
      "            82/\n",
      "                420da7ef106703fc8db52563cd216941a9e7c2\n",
      "            90/\n",
      "                c5365492dea3b3c855b2375f1de8588ac1bda4\n",
      "            a0/\n",
      "                045f79b8b37b1a8154e8ddb51fcf794a021f94\n",
      "            a7/\n",
      "                194965f1884d29f9cc8269d520054734a60ed1\n",
      "            a8/\n",
      "                057ee98207924b4926f82cd9a67ddd987023cc\n",
      "            b2/\n",
      "                8d1896309bee266f1a63819bf80e5028e452ea\n",
      "            bb/\n",
      "                81b9a0568d8cb5f9b8cade97bebf57e80b0a9c\n",
      "            c2/\n",
      "                1bc6bb1080e64a3c729c4ba5c8e48a6624fa25\n",
      "            ca/\n",
      "                2858ec00541db4aee0f113b0537e441c2da862\n",
      "            ce/\n",
      "                0dc92c97ef33fcbbfaedf7a96ef51a3c67d2f2\n",
      "            e0/\n",
      "                4dcd2597373cdd003854989ea712c29cded554\n",
      "            info/\n",
      "            pack/\n",
      "                pack-f2981570e88e9bd5e858267818b76b149629a302.idx\n",
      "                pack-f2981570e88e9bd5e858267818b76b149629a302.pack\n",
      "                pack-f2981570e88e9bd5e858267818b76b149629a302.rev\n",
      "        refs/\n",
      "            heads/\n",
      "                main\n",
      "                nam\n",
      "            remotes/\n",
      "                origin/\n",
      "                    HEAD\n",
      "                    main\n",
      "                    nam\n",
      "            tags/\n",
      "    cifar-10-batches-py/\n",
      "        batches.meta\n",
      "        data_batch_1\n",
      "        data_batch_2\n",
      "        data_batch_3\n",
      "        data_batch_4\n",
      "        data_batch_5\n",
      "        readme.html\n",
      "        test_batch\n"
     ]
    }
   ],
   "source": [
    "# in c√¢y th∆∞ m·ª•c hi·ªán t·∫°i\n",
    "def print_directory_tree(path='.'):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        level = root.replace(path, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f\"{subindent}{f}\")\n",
    "\n",
    "print(\"üìÇ Current directory tree:\")\n",
    "print_directory_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Phi√™n b·∫£n ƒë∆∞·ª£c vi·∫øt b·∫±ng python thu·∫ßn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Class Conv2D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(input_data, pad):\n",
    "        H, W, C = len(input_data), len(input_data[0]), len(input_data[0][0])\n",
    "        padded = [[[0.0 for _ in range(C)] for _ in range(W + 2 * pad)] for _ in range(H + 2 * pad)]\n",
    "        \n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                for c in range(C):\n",
    "                    padded[i + pad][j + pad][c] = input_data[i][j][c]\n",
    "        \n",
    "        return padded\n",
    "\n",
    "class Conv2D:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=0, stride=1):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "        self.kernels = [[[[random.uniform(-0.1, 0.1)\n",
    "            for _ in range(out_channels)]\n",
    "            for _ in range(in_channels)]\n",
    "            for _ in range(kernel_size)]\n",
    "            for _ in range(kernel_size)]\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        pad = self.padding\n",
    "        stride = self.stride\n",
    "        k = self.kernel_size\n",
    "        cin = self.in_channels\n",
    "        cout = self.out_channels\n",
    "\n",
    "        input_padded = zero_pad(input_data, pad)\n",
    "        self.input_padded = input_padded\n",
    "\n",
    "        H, W, _ = len(input_padded), len(input_padded[0]), len(input_padded[0][0])\n",
    "        out_h = (H - k) // stride + 1\n",
    "        out_w = (W - k) // stride + 1\n",
    "\n",
    "        output = [[[0.0 for _ in range(cout)] for _ in range(out_w)] for _ in range(out_h)]\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                for cout_idx in range(cout):\n",
    "                    val = 0.0\n",
    "                    for u in range(k):\n",
    "                        for v in range(k):\n",
    "                            for cin_idx in range(cin):\n",
    "                                x = i * stride + u\n",
    "                                y = j * stride + v\n",
    "                                val += input_padded[x][y][cin_idx] * self.kernels[u][v][cin_idx][cout_idx]\n",
    "                    output[i][j][cout_idx] = val\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        pad = self.padding\n",
    "        stride = self.stride\n",
    "        k = self.kernel_size\n",
    "        cin = self.in_channels\n",
    "        cout = self.out_channels\n",
    "        input_padded = self.input_padded\n",
    "        H, W, _ = len(input_padded), len(input_padded[0]), len(input_padded[0][0])\n",
    "        out_h = len(grad_output)\n",
    "        out_w = len(grad_output[0])\n",
    "\n",
    "        grad_input_padded = [[[0.0 for _ in range(cin)] for _ in range(W)] for _ in range(H)]\n",
    "        grad_kernels = [[[[0.0 for _ in range(cout)] for _ in range(cin)] for _ in range(k)] for _ in range(k)]\n",
    "\n",
    "        for u in range(k):\n",
    "            for v in range(k):\n",
    "                for cin_idx in range(cin):\n",
    "                    for cout_idx in range(cout):\n",
    "                        grad = 0.0\n",
    "                        for i in range(out_h):\n",
    "                            for j in range(out_w):\n",
    "                                x = i * stride + u\n",
    "                                y = j * stride + v\n",
    "                                grad += input_padded[x][y][cin_idx] * grad_output[i][j][cout_idx]\n",
    "                        grad_kernels[u][v][cin_idx][cout_idx] = grad\n",
    "\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                for cin_idx in range(cin):\n",
    "                    grad = 0.0\n",
    "                    for u in range(k):\n",
    "                        for v in range(k):\n",
    "                            for cout_idx in range(cout):\n",
    "                                x = i - u\n",
    "                                y = j - v\n",
    "                                if 0 <= x // stride < out_h and 0 <= y // stride < out_w:\n",
    "                                    if x % stride == 0 and y % stride == 0:\n",
    "                                        grad += grad_output[x // stride][y // stride][cout_idx] * self.kernels[u][v][cin_idx][cout_idx]\n",
    "                    grad_input_padded[i][j][cin_idx] = grad\n",
    "\n",
    "        if pad > 0:\n",
    "            grad_input = [ [ row[pad:-pad] for row in layer[pad:-pad] ] for layer in [grad_input_padded] ][0]\n",
    "        else:\n",
    "            grad_input = grad_input_padded\n",
    "\n",
    "        self.grad_kernels = grad_kernels  # L∆∞u ƒë·ªÉ update sau\n",
    "        return grad_input\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        for u in range(self.kernel_size):\n",
    "            for v in range(self.kernel_size):\n",
    "                for cin_idx in range(self.in_channels):\n",
    "                    for cout_idx in range(self.out_channels):\n",
    "                        self.kernels[u][v][cin_idx][cout_idx] -= learning_rate * self.grad_kernels[u][v][cin_idx][cout_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Class ReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.input = x  # L∆∞u input Z ƒë·ªÉ d√πng trong backward\n",
    "        H, W, C = len(x), len(x[0]), len(x[0][0])\n",
    "        output = [[[max(0, x[i][j][c]) for c in range(C)] for j in range(W)] for i in range(H)]\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        H, W, C = len(self.input), len(self.input[0]), len(self.input[0][0])\n",
    "        grad_input = [[[0.0 for _ in range(C)] for _ in range(W)] for _ in range(H)]\n",
    "\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                for c in range(C):\n",
    "                    grad_input[i][j][c] = grad_output[i][j][c] if self.input[i][j][c] > 0 else 0.0\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Class MaxPool2D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, kernel_size=2, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x  # l∆∞u l·∫°i input cho backward\n",
    "        H_in, W_in, C = len(x), len(x[0]), len(x[0][0])\n",
    "        H_out = (H_in - self.kernel_size) // self.stride + 1\n",
    "        W_out = (W_in - self.kernel_size) // self.stride + 1\n",
    "\n",
    "        self.output = [[[0 for _ in range(C)] for _ in range(W_out)] for _ in range(H_out)]\n",
    "        self.max_indices = [[[(-1, -1) for _ in range(C)] for _ in range(W_out)] for _ in range(H_out)]\n",
    "\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                for c in range(C):\n",
    "                    max_val = float('-inf')\n",
    "                    max_idx = (0, 0)\n",
    "                    for u in range(self.kernel_size):\n",
    "                        for v in range(self.kernel_size):\n",
    "                            x_idx = i * self.stride + u\n",
    "                            y_idx = j * self.stride + v\n",
    "                            val = x[x_idx][y_idx][c]\n",
    "                            if val > max_val:\n",
    "                                max_val = val\n",
    "                                max_idx = (x_idx, y_idx)\n",
    "                    self.output[i][j][c] = max_val\n",
    "                    self.max_indices[i][j][c] = max_idx\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        H_in, W_in, C = len(self.input), len(self.input[0]), len(self.input[0][0])\n",
    "        H_out, W_out = len(d_out), len(d_out[0])\n",
    "\n",
    "        d_input = [[[0.0 for _ in range(C)] for _ in range(W_in)] for _ in range(H_in)]\n",
    "\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                for c in range(C):\n",
    "                    max_x, max_y = self.max_indices[i][j][c]\n",
    "                    d_input[max_x][max_y][c] += d_out[i][j][c]\n",
    "        return d_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conv Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock:\n",
    "    def __init__(self, in_channels, out_channels, num_convs=2, padding=0, stride=1):\n",
    "        self.convs = []\n",
    "        self.relus = []  # T√°ch ri√™ng ReLU cho t·ª´ng Conv\n",
    "        for _ in range(num_convs):\n",
    "            conv = Conv2D(in_channels, out_channels, kernel_size=3, padding=padding, stride=stride)\n",
    "            relu = ReLU()\n",
    "            self.convs.append(conv)\n",
    "            self.relus.append(relu)\n",
    "            in_channels = out_channels\n",
    "        self.pool = MaxPool2D(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.inputs = []  # L∆∞u t·ª´ng ƒë·∫ßu v√†o cho t·ª´ng Conv layer\n",
    "        x = input\n",
    "        for conv, relu in zip(self.convs, self.relus):\n",
    "            x = conv.forward(x)\n",
    "            self.inputs.append(x)  # L∆∞u sau m·ªói conv tr∆∞·ªõc ReLU\n",
    "            x = relu.forward(x)\n",
    "        x = self.pool.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        # Backward qua MaxPool\n",
    "        d_out = self.pool.backward(d_out)\n",
    "\n",
    "        # Backward qua c√°c Conv v√† ReLU theo th·ª© t·ª± ng∆∞·ª£c l·∫°i\n",
    "        for conv, relu in zip(reversed(self.convs), reversed(self.relus)):\n",
    "            d_out = relu.backward(d_out)\n",
    "            d_out = conv.backward(d_out)\n",
    "\n",
    "        return d_out\n",
    "    \n",
    "    def step(self, learning_rate):\n",
    "        for conv in self.convs:\n",
    "            conv.step(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Flatten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuy·ªÉn 3D vector th√†nh 1D vector\n",
    "class Flatten:\n",
    "    def forward(self, input):\n",
    "        self.input_shape = (len(input), len(input[0]), len(input[0][0]))  # (H, W, C)\n",
    "        output = []\n",
    "        for h in range(self.input_shape[0]):\n",
    "            for w in range(self.input_shape[1]):\n",
    "                for c in range(self.input_shape[2]):\n",
    "                    output.append(input[h][w][c])\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        H, W, C = self.input_shape\n",
    "        output = [[[0.0 for _ in range(C)] for _ in range(W)] for _ in range(H)]\n",
    "        idx = 0\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                for c in range(C):\n",
    "                    output[h][w][c] = grad_output[idx]\n",
    "                    idx += 1\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Fully Connected Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.W = [[random.uniform(-0.01, 0.01) for _ in range(out_dim)] for _ in range(in_dim)]\n",
    "        self.b = [0.0 for _ in range(out_dim)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        output = []\n",
    "        for k in range(self.out_dim):\n",
    "            y_k = self.b[k]\n",
    "            for d in range(self.in_dim):\n",
    "                y_k += self.W[d][k] * x[d]\n",
    "            output.append(y_k)\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = [0.0 for _ in range(self.in_dim)]\n",
    "        grad_W = [[0.0 for _ in range(self.out_dim)] for _ in range(self.in_dim)]\n",
    "        grad_b = [0.0 for _ in range(self.out_dim)]\n",
    "\n",
    "        for d in range(self.in_dim):\n",
    "            for k in range(self.out_dim):\n",
    "                grad_input[d] += self.W[d][k] * grad_output[k]\n",
    "\n",
    "        for d in range(self.in_dim):\n",
    "            for k in range(self.out_dim):\n",
    "                grad_W[d][k] = self.input[d] * grad_output[k]\n",
    "\n",
    "        for k in range(self.out_dim):\n",
    "            grad_b[k] = grad_output[k]\n",
    "\n",
    "        self.grad_W = grad_W\n",
    "        self.grad_b = grad_b\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        for d in range(self.in_dim):\n",
    "            for k in range(self.out_dim):\n",
    "                self.W[d][k] -= learning_rate * self.grad_W[d][k]\n",
    "        for k in range(self.out_dim):\n",
    "            self.b[k] -= learning_rate * self.grad_b[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ReLU cho vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUVector:\n",
    "    def forward(self, x):\n",
    "        self.input = x  # l∆∞u input ƒë·ªÉ backward\n",
    "        return [max(0, v) for v in x]\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = []\n",
    "        for i in range(len(self.input)):\n",
    "            if self.input[i] > 0:\n",
    "                grad_input.append(grad_output[i])\n",
    "            else:\n",
    "                grad_input.append(0.0)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Softmax + CrossEntropyLoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, x):\n",
    "        self.input = x  # l∆∞u input ƒë·ªÉ n·∫øu c·∫ßn debug\n",
    "        max_x = max(x)  # ch·ªëng tr√†n s·ªë\n",
    "        exps = [math.exp(v - max_x) for v in x]\n",
    "        sum_exps = sum(exps)\n",
    "        self.output = [v / sum_exps for v in exps]\n",
    "        return self.output\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def forward(self, pred_probs, target_onehot):\n",
    "        self.pred_probs = pred_probs  # l∆∞u l·∫°i cho backward\n",
    "        self.target_onehot = target_onehot\n",
    "        loss = 0.0\n",
    "        for i in range(len(pred_probs)):\n",
    "            loss -= target_onehot[i] * math.log(pred_probs[i] + 1e-12)\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        grad = []\n",
    "        for i in range(len(self.pred_probs)):\n",
    "            grad.append(self.pred_probs[i] - self.target_onehot[i])\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H√†m b·ªï tr·ª£ log th√¥ng tin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_training_details(epoch, epochs, epoch_time, n_samples, loss, accuracy, filename):\n",
    "    # T·∫°o file n·∫øu ch∆∞a c√≥\n",
    "    is_new_file = not os.path.exists(filename)\n",
    "\n",
    "    with open(filename, \"a\") as file:\n",
    "        # Ghi ti√™u ƒë·ªÅ n·∫øu file m·ªõi\n",
    "        if is_new_file:\n",
    "            file.write(\"Epoch,Total Epochs,Epoch Time (s),Time per Step (ms),Loss,Accuracy\\n\")\n",
    "\n",
    "        # T√≠nh th·ªùi gian m·ªói b∆∞·ªõc (millisecond)\n",
    "        time_per_step = (epoch_time * 1000) / n_samples\n",
    "\n",
    "        # Ghi chi ti·∫øt qu√° tr√¨nh hu·∫•n luy·ªán\n",
    "        file.write(f\"{epoch+1},{epochs},{epoch_time:.6f},{time_per_step:.6f},{loss:.6f},{accuracy:.6f}\\n\")\n",
    "\n",
    "def log_details(id, n_epochs,\n",
    "                conv2d_time, relu_time, maxpool_time,\n",
    "                flatten_time, fc_time, softmax_time,\n",
    "                filename):\n",
    "    import os\n",
    "    is_new_file = not os.path.exists(filename)\n",
    "\n",
    "    with open(filename, \"a\") as file:\n",
    "        if is_new_file:\n",
    "            file.write(\"ID,Total Epochs,Conv2D Time (s),ReLU Time (s),MaxPool2D Time (s),Flatten Time (s),FullyConnected Time (s),Softmax Time (s)\\n\")\n",
    "\n",
    "        file.write(f\"{id},{n_epochs},\"\n",
    "                   f\"{conv2d_time:.6f},{relu_time:.6f},{maxpool_time:.6f},\"\n",
    "                   f\"{flatten_time:.6f},{fc_time:.6f},{softmax_time:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Class C·∫•u tr√∫c**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    def __init__(self):\n",
    "        self.block1 = ConvBlock(3, 64, num_convs=2, padding=1)\n",
    "        self.block2 = ConvBlock(64, 128, num_convs=2, padding=1)\n",
    "        self.block3 = ConvBlock(128, 256, num_convs=2, padding=1)\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = FullyConnected(256 * 4 * 4, 512)  # Sau 3 l·∫ßn pooling 2x2, ·∫£nh c√≤n 4x4\n",
    "        self.relu_fc1 = ReLUVector()\n",
    "        self.fc2 = FullyConnected(512, 10)\n",
    "        self.softmax = Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, train_labels, epochs=10, learning_rate=0.01, mb_size=32, \n",
    "          log_filename=\"training_log.csv\", detail_log_filename=\"details_log.csv\"):\n",
    "    random.seed(0)\n",
    "    cross_entropy = CrossEntropyLoss()\n",
    "\n",
    "    n_samples = len(train_data)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "\n",
    "        conv2d_time = relu_time = maxpool_time = flatten_time = fc_time = softmax_time = 0.0\n",
    "\n",
    "        # Shuffle data\n",
    "        indices = list(range(n_samples))\n",
    "        random.shuffle(indices)\n",
    "        train_data_shuffled = [train_data[i] for i in indices]\n",
    "        train_labels_shuffled = [train_labels[i] for i in indices]\n",
    "\n",
    "        # Mini-batch training\n",
    "        full_batch_count = n_samples // mb_size\n",
    "        for i in range(full_batch_count):\n",
    "            start = i * mb_size\n",
    "            end = start + mb_size\n",
    "            X_batch = train_data_shuffled[start:end]\n",
    "            y_batch = train_labels_shuffled[start:end]\n",
    "\n",
    "            # Train each sample in batch\n",
    "            for x, target in zip(X_batch, y_batch):\n",
    "                ## Forward pass\n",
    "                t0 = time.time()\n",
    "                out = model.block1.forward(x)\n",
    "                t1 = time.time()\n",
    "                conv2d_time += t1 - t0\n",
    "\n",
    "                t0 = time.time()\n",
    "                out = model.block2.forward(out)\n",
    "                t1 = time.time()\n",
    "                conv2d_time += t1 - t0\n",
    "\n",
    "                t0 = time.time()\n",
    "                out = model.block3.forward(out)\n",
    "                t1 = time.time()\n",
    "                conv2d_time += t1 - t0\n",
    "\n",
    "                t0 = time.time()\n",
    "                out = model.flatten.forward(out)\n",
    "                t1 = time.time()\n",
    "                flatten_time += t1 - t0\n",
    "\n",
    "                t0 = time.time()\n",
    "                out = model.fc1.forward(out)\n",
    "                t1 = time.time()\n",
    "                fc_time += t1 - t0\n",
    "\n",
    "                t0 = time.time()\n",
    "                out = model.relu_fc1.forward(out)\n",
    "                t1 = time.time()\n",
    "                relu_time += t1 - t0\n",
    "\n",
    "                t0 = time.time()\n",
    "                out = model.fc2.forward(out)\n",
    "                t1 = time.time()\n",
    "                fc_time += t1 - t0\n",
    "\n",
    "                t0 = time.time()\n",
    "                pred_probs = model.softmax.forward(out)\n",
    "                t1 = time.time()\n",
    "                softmax_time += t1 - t0\n",
    "\n",
    "                loss = cross_entropy.forward(pred_probs, target)\n",
    "                total_loss += loss\n",
    "\n",
    "                pred_label = pred_probs.index(max(pred_probs))\n",
    "                true_label = target.index(max(target))\n",
    "                if pred_label == true_label:\n",
    "                    correct += 1\n",
    "\n",
    "                ## Backward pass\n",
    "                grad = [pred_probs[i] - target[i] for i in range(len(target))]\n",
    "\n",
    "                grad = model.fc2.backward(grad)\n",
    "                grad = model.relu_fc1.backward(grad)\n",
    "                grad = model.fc1.backward(grad)\n",
    "                grad = model.flatten.backward(grad)\n",
    "                grad = model.block3.backward(grad)\n",
    "                grad = model.block2.backward(grad)\n",
    "                grad = model.block1.backward(grad)\n",
    "\n",
    "                ## Update weights\n",
    "                model.fc2.step(learning_rate)\n",
    "                model.fc1.step(learning_rate)\n",
    "                model.block3.step(learning_rate)\n",
    "                model.block2.step(learning_rate)\n",
    "                model.block1.step(learning_rate)\n",
    "\n",
    "        # End of epoch\n",
    "        end_epoch = time.time()\n",
    "        epoch_time = end_epoch - start_epoch\n",
    "        accuracy = correct / (full_batch_count * mb_size)\n",
    "\n",
    "        # Logging\n",
    "        log_training_details(epoch, epochs, epoch_time, n_samples, total_loss / (full_batch_count * mb_size), accuracy, log_filename)\n",
    "        log_details(f\"Epoch_{epoch+1}\", mb_size, conv2d_time, relu_time, maxpool_time, flatten_time, fc_time, softmax_time, detail_log_filename)\n",
    "\n",
    "        # Print\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/(full_batch_count * mb_size):.4f} - Acc: {accuracy:.4f} - Time: {epoch_time:.2f}s\")\n",
    "        print(f\"    Conv2D: {conv2d_time:.2f}s | ReLU: {relu_time:.2f}s | MaxPool: {maxpool_time:.2f}s | Flatten: {flatten_time:.2f}s | FC: {fc_time:.2f}s | Softmax: {softmax_time:.2f}s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 2.8780 - Acc: 0.1000 - Time: 946.01s\n",
      "Epoch 2/5 - Loss: 3.9017 - Acc: 0.3000 - Time: 930.31s\n",
      "Epoch 3/5 - Loss: 2.9802 - Acc: 0.1000 - Time: 922.13s\n",
      "Epoch 4/5 - Loss: 2.6948 - Acc: 0.2000 - Time: 922.21s\n",
      "Epoch 5/5 - Loss: 2.6293 - Acc: 0.2000 - Time: 929.79s\n"
     ]
    }
   ],
   "source": [
    "# # Gi·∫£ l·∫≠p b·ªô d·ªØ li·ªáu nh·ªè\n",
    "# train_data = [[[ [random.uniform(0, 1) for _ in range(3)] for _ in range(32)] for _ in range(32)] for _ in range(10)]  # 10 ·∫£nh 32x32x3\n",
    "# train_labels = [[1 if i == random.randint(0,9) else 0 for i in range(10)] for _ in range(10)]  # 10 nh√£n one-hot\n",
    "\n",
    "# # Kh·ªüi t·∫°o model\n",
    "# model = SimpleCNN()\n",
    "\n",
    "# # Train\n",
    "# train(model, train_data, train_labels, epochs=5, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_cifar10_data()\n",
    "\n",
    "# Convert numpy arrays to pure Python lists\n",
    "X_train = X_train.tolist()\n",
    "y_train = y_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "# Convert from (3, 32, 32) -> (32, 32, 3)\n",
    "def transpose_channels(img):\n",
    "    C, H, W = len(img), len(img[0]), len(img[0][0])\n",
    "    transposed = [[[0.0 for _ in range(C)] for _ in range(W)] for _ in range(H)]\n",
    "    for c in range(C):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                transposed[h][w][c] = img[c][h][w]\n",
    "    return transposed\n",
    "\n",
    "X_train = [transpose_channels(img) for img in X_train]\n",
    "X_test = [transpose_channels(img) for img in X_test]\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "def normalize_image(img):\n",
    "    H, W, C = len(img), len(img[0]), len(img[0][0])\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for c in range(C):\n",
    "                img[h][w][c] /= 255.0\n",
    "    return img\n",
    "\n",
    "X_train = [normalize_image(img) for img in X_train]\n",
    "X_test = [normalize_image(img) for img in X_test]\n",
    "\n",
    "# One-hot encoding labels\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    one_hot = []\n",
    "    for label in labels:\n",
    "        vec = [0.0] * num_classes\n",
    "        vec[label] = 1.0\n",
    "        one_hot.append(vec)\n",
    "    return one_hot\n",
    "\n",
    "y_train = one_hot_encode(y_train)\n",
    "y_test = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1 epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "\n",
    "train(model, X_train, y_train, epochs=1, learning_rate=0.01, mb_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H√†m conv2d()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "    X: Input image, shape (C_in, H, W)\n",
    "    K: Filter weights, shape (C_out, C_in, kH, kW)\n",
    "    stride: b∆∞·ªõc di chuy·ªÉn\n",
    "    padding: s·ªë pixel pad xung quanh ·∫£nh\n",
    "\n",
    "    Tr·∫£ v·ªÅ: Feature map, shape (C_out, H_out, W_out)\n",
    "    \"\"\"\n",
    "    C_in, H, W = X.shape\n",
    "    C_out, _, kH, kW = K.shape\n",
    "\n",
    "    # Pad input n·∫øu c·∫ßn\n",
    "    if padding > 0:\n",
    "        X_padded = np.pad(X, ((0,0), (padding,padding), (padding,padding)), mode='constant')\n",
    "    else:\n",
    "        X_padded = X\n",
    "\n",
    "    H_out = (H + 2*padding - kH) // stride + 1\n",
    "    W_out = (W + 2*padding - kW) // stride + 1\n",
    "    Y = np.zeros((C_out, H_out, W_out), dtype=np.float32)\n",
    "\n",
    "    for cout in range(C_out):\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                for cin in range(C_in):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    region = X_padded[cin, h_start:h_start+kH, w_start:w_start+kW]\n",
    "                    Y[cout, i, j] += np.sum(region * K[cout, cin])\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conv2D output: (64, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Test h√†m conv2d\n",
    "X = np.random.rand(3, 32, 32)         # Input: 3 channels (RGB), 32x32\n",
    "K = np.random.rand(64, 3, 3, 3)       # 64 filters, m·ªói filter 3x3x3\n",
    "\n",
    "out = conv2d(X, K, stride=1, padding=1)\n",
    "print(\"‚úÖ Conv2D output:\", out.shape)  # K·∫øt qu·∫£: (64, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numba\n",
      "  Downloading numba-0.61.2-cp312-cp312-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.24 in c:\\users\\win 10\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from numba) (1.26.4)\n",
      "Downloading numba-0.61.2-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.3/2.8 MB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.9/30.3 MB 21.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 7.1/30.3 MB 16.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 8.4/30.3 MB 13.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 9.7/30.3 MB 11.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 10.7/30.3 MB 10.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 12.1/30.3 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 13.1/30.3 MB 8.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 14.4/30.3 MB 8.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 15.7/30.3 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 17.0/30.3 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 18.4/30.3 MB 7.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 19.9/30.3 MB 7.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 21.2/30.3 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 22.8/30.3 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.4/30.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 26.0/30.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 27.8/30.3 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 29.4/30.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.44.0 numba-0.61.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\WIN 10\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def pad2d_manual(X, pad):\n",
    "    C, H, W = X.shape\n",
    "    X_padded = np.zeros((C, H + 2*pad, W + 2*pad), dtype=X.dtype)\n",
    "    for c in range(C):\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                X_padded[c, i + pad, j + pad] = X[c, i, j]\n",
    "    return X_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit  # kh√¥ng d√πng parallel ƒë·ªÉ ƒë·∫£m b·∫£o logic tu·∫ßn t·ª±\n",
    "def conv2d_fast(X, K, stride=1, padding=1):\n",
    "    C_in, H, W = X.shape\n",
    "    C_out, _, kH, kW = K.shape\n",
    "\n",
    "    if padding > 0:\n",
    "        X_padded = pad2d_manual(X, padding)\n",
    "    else:\n",
    "        X_padded = X\n",
    "\n",
    "    H_out = (H + 2*padding - kH) // stride + 1\n",
    "    W_out = (W + 2*padding - kW) // stride + 1\n",
    "    Y = np.zeros((C_out, H_out, W_out), dtype=np.float32)\n",
    "\n",
    "    for cout in range(C_out):\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                for cin in range(C_in):\n",
    "                    for u in range(kH):\n",
    "                        for v in range(kW):\n",
    "                            Y[cout, i, j] += X_padded[cin, i*stride + u, j*stride + v] * K[cout, cin, u, v]\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H√†m ReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return np.maximum(0, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Max Pooling 2x2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2x2(X):\n",
    "    \"\"\"\n",
    "    X: Input feature map, shape (C, H, W)\n",
    "    Returns: Downsampled feature map, shape (C, H//2, W//2)\n",
    "    \"\"\"\n",
    "    C, H, W = X.shape\n",
    "    out_H, out_W = H // 2, W // 2\n",
    "    pooled = np.zeros((C, out_H, out_W), dtype=np.float32)\n",
    "\n",
    "    for c in range(C):\n",
    "        for i in range(out_H):\n",
    "            for j in range(out_W):\n",
    "                region = X[c, i*2:i*2+2, j*2:j*2+2]\n",
    "                pooled[c, i, j] = np.max(region)\n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Block 1 + 2 + 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output Block 1: (64, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# # Kh·ªüi t·∫°o ng·∫´u nhi√™n c√°c filter Conv\n",
    "# np.random.seed(42)\n",
    "# K1 = np.random.randn(64, 3, 3, 3) * 0.1  # 64 filters, 3x3, input 3 channels\n",
    "# K2 = np.random.randn(64, 64, 3, 3) * 0.1  # 64 filters, 3x3, input 64 channels\n",
    "\n",
    "# def block1(X):\n",
    "#     out = conv2d(X, K1, stride=1, padding=1)\n",
    "#     out = relu(out)\n",
    "#     out = conv2d(out, K2, stride=1, padding=1)\n",
    "#     out = relu(out)\n",
    "#     out = max_pool2x2(out)\n",
    "#     return out\n",
    "\n",
    "# # Th·ª≠ v·ªõi ·∫£nh ƒë·∫ßu ti√™n\n",
    "# out_block1 = block1(X_train[0])\n",
    "# print(\"‚úÖ Output Block 1:\", out_block1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o ng·∫´u nhi√™n c√°c filter Conv\n",
    "# Block 1\n",
    "np.random.seed(42)\n",
    "K1 = np.random.randn(64, 3, 3, 3) * 0.1  # 64 filters, 3x3, input 3 channels\n",
    "K2 = np.random.randn(64, 64, 3, 3) * 0.1  # 64 filters, 3x3, input 64 channels\n",
    "\n",
    "# Block 2\n",
    "K3 = np.random.randn(128, 64, 3, 3) * 0.1  # 128 filters, 3x3, input 64 channels\n",
    "K4 = np.random.randn(128, 128, 3, 3) * 0.1  # 128 filters, 3x3, input 128 channels\n",
    "\n",
    "# Block 3\n",
    "K5 = np.random.randn(256, 128, 3, 3) * 0.1  # 256 filters, 3x3, input 128 channels\n",
    "K6 = np.random.randn(256, 256, 3, 3) * 0.1  # 256 filters, 3x3, input 256 channels\n",
    "\n",
    "def block1_fast(X):\n",
    "    out = conv2d_fast(X, K1, stride=1, padding=1)\n",
    "    out = relu(out)\n",
    "    out = conv2d_fast(out, K2, stride=1, padding=1)\n",
    "    out = relu(out)\n",
    "    out = max_pool2x2(out)\n",
    "    return out\n",
    "\n",
    "def block2_fast(X):\n",
    "    out = conv2d_fast(X, K3, stride=1, padding=1)\n",
    "    out = relu(out)\n",
    "    out = conv2d_fast(out, K4, stride=1, padding=1)\n",
    "    out = relu(out)\n",
    "    out = max_pool2x2(out)\n",
    "    return out\n",
    "\n",
    "def block3_fast(X):\n",
    "    out = conv2d_fast(X, K5, stride=1, padding=1)\n",
    "    out = relu(out)\n",
    "    out = conv2d_fast(out, K6, stride=1, padding=1)\n",
    "    out = relu(out)\n",
    "    out = max_pool2x2(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output Block 1 (fast): (64, 16, 16)\n",
      "‚úÖ Output Block 2 (fast): (128, 8, 8)\n",
      "‚úÖ Output Block 3 (fast): (256, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# Th·ª≠ v·ªõi ·∫£nh ƒë·∫ßu ti√™n\n",
    "out_block1_fast = block1_fast(X_train[0])\n",
    "print(\"‚úÖ Output Block 1 (fast):\", out_block1_fast.shape)\n",
    "out_block2_fast = block2_fast(out_block1_fast)\n",
    "print(\"‚úÖ Output Block 2 (fast):\", out_block2_fast.shape)\n",
    "out_block3_fast = block3_fast(out_block2_fast)\n",
    "print(\"‚úÖ Output Block 3 (fast):\", out_block3_fast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten: (256, 4, 4) ‚Üí 256*4*4 = 4096 ƒë·∫ßu v√†o\n",
    "W1 = np.random.randn(512, 256 * 4 * 4) * 0.1  # FC: 4096 ‚Üí 512\n",
    "b1 = np.zeros((512,))\n",
    "\n",
    "W2 = np.random.randn(10, 512) * 0.1  # FC: 512 ‚Üí 10\n",
    "b2 = np.zeros((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_forward(X, W, b):\n",
    "    return np.dot(W, X) + b\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))  # Tr√°nh overflow\n",
    "    return e_x / np.sum(e_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    out = block1_fast(X)\n",
    "    out = block2_fast(out)\n",
    "    out = block3_fast(out)\n",
    "    \n",
    "    out = out.reshape(-1)  # Flatten: (256,4,4) -> (4096,)\n",
    "    \n",
    "    out = fc_forward(out, W1, b1)\n",
    "    out = relu(out)\n",
    "    \n",
    "    out = fc_forward(out, W2, b2)\n",
    "    out = softmax(out)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output of the network: (10,)\n",
      "‚úÖ Predicted class: 2\n",
      "‚úÖ True class: 6\n"
     ]
    }
   ],
   "source": [
    "# Th·ª≠ v·ªõi ·∫£nh ƒë·∫ßu ti√™n\n",
    "out = forward(X_train[0])\n",
    "print(\"‚úÖ Output of the network:\", out.shape)\n",
    "print(\"‚úÖ Predicted class:\", np.argmax(out))\n",
    "print(\"‚úÖ True class:\", y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    return -np.log(y_pred[y_true] + 1e-9)  # Tr√°nh log(0)\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return int(np.argmax(y_pred) == y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss: 20.72326583694641\n",
      "üéØ Accuracy: 0\n"
     ]
    }
   ],
   "source": [
    "y_pred = forward(X_train[0])\n",
    "loss = cross_entropy_loss(y_pred, y_train[0])\n",
    "acc = accuracy(y_pred, y_train[0])\n",
    "\n",
    "print(\"üìâ Loss:\", loss)\n",
    "print(\"üéØ Accuracy:\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
